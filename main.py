# -*- coding: utf-8 -*-
"""Untitled.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17wk6Rmvhkd8asNlpv9gyc6fJIiAndOyy
"""

import math
import yfinance as yf
from pandas_datareader import data as pdr
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
from keras.models import Sequential
from keras.layers import Dense, LSTM
import matplotlib.pyplot as plt
from datetime import datetime
from datetime import timedelta
pd.options.mode.chained_assignment = None

acao = "PETR4.SA"

inicio = "2010-12-31"
final = "2023-12-27"

dados_acao = yf.download(acao, start=inicio, end=final)

dados_acao

# não pode ser ajustados

cotacao = dados_acao['Close'].to_numpy().reshape(-1, 1)

cotacao

tamanho_dados_treinamento = int(len(cotacao) * 0.8)

tamanho_dados_treinamento

# Escalar os dados entre 0 e 1, para deixar mais facil o precessamento
# Dados em escola pré definidos são masi faceis de lidar

escalador = MinMaxScaler(feature_range=(0, 1))

dados_entre_0_1_trei = escalador.fit_transform(cotacao[0: tamanho_dados_treinamento, :])

dados_entre_0_1_teste = escalador.transform(cotacao[tamanho_dados_treinamento: , :])

dados_entre_0_1 = list(dados_entre_0_1_trei.reshape(len(dados_entre_0_1_trei))) + list(dados_entre_0_1_teste.reshape(len(dados_entre_0_1_teste)))

dados_entre_0_1 = np.array(dados_entre_0_1).reshape(len(dados_entre_0_1), 1)

dados_entre_0_1

dados_para_treinamento = dados_entre_0_1[0: tamanho_dados_treinamento, :]

#dados que serão usados para gerar o resultado
treinamento_x = []

#cotação que aconteceu de fato
treinamento_y = []

for i in range(60, len(dados_para_treinamento)):

    #ultimos 60 dias
    treinamento_x.append(dados_para_treinamento[i -60: i, 0])
    #cotação
    treinamento_y.append(dados_para_treinamento[i, 0])

    if i <= 61:

        print(treinamento_x)
        print(treinamento_y)

#tranformando as listas em arrays e dando reshape 3d

treinamento_x, treinamento_y = np.array(treinamento_x), np.array(treinamento_y)

print(treinamento_x)

treinamento_x = treinamento_x.reshape(treinamento_x.shape[0] , treinamento_x.shape[1], 1)

treinamento_x

#contruindo o modelo

modelo= Sequential()


#vamos criar um modelo com 50 neuronios
#return sequence = True pois vamos usar em LSTM depois
#definir o shape, que ni caso são 60 informções par gerar uma
#adicionar mais neuronios com dense, 25 e 1
#não se apegue a lista agora, e apenas uma arquitetura de deep learning

modelo.add(LSTM(50, return_sequences=True, input_shape = (treinamento_x.shape[1], 1)))
modelo.add(LSTM(50, return_sequences=False))
modelo.add(Dense(25))
modelo.add(Dense(1))

treinamento_x.shape[1]

#copilando o modelo

# a funcao de loss é a forma de medir o erro do modelo, que nesse caso
#é o calssico erro médio quadrantico do que e usado em regresão linear
#otimizador e média de erro

modelo.compile(optimizer='adam', loss='mean_squared_error')

#agora com modelo compilado e os dados, podemos treinar o modelo
#batch size é depois de quantas em quantas amostras o modelo ira orimizar os parametros
#epochs é quantas vezes o algoritimo ira rodas os dados treinamento, aprendendo

modelo.fit(treinamento_x, treinamento_y, batch_size=1, epochs=1)

#criar dados de teste

dados_teste = dados_entre_0_1[tamanho_dados_treinamento - 60:, :]

teste_x = []
teste_y = cotacao[tamanho_dados_treinamento: , :]

for i in range(60, len(dados_teste)):
    teste_x.append(dados_teste[i - 60: i, 0])

#reshape
teste_x = np.array(teste_x)
teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)

#pegando predições do modelo

predicoes = modelo.predict(teste_x)

# tirando escala dos dados

predicoes = escalador.inverse_transform(predicoes)

predicoes

#pegando o erro medio quadratico (RMSE)

rmse = np.sqrt(np.mean(predicoes - teste_y) ** 2)
rmse

#criando o grafico do modelo

treinamento = dados_acao.iloc[:tamanho_dados_treinamento, :]
df_teste = pd.DataFrame({'Close': dados_acao['Close'].iloc[tamanho_dados_treinamento:],
                        'predicoes': predicoes.reshape(len(predicoes))})

plt.figure(figsize = (16, 8))
plt.title('Modelo')
plt.xlabel('Data', fontsize = 18)
plt.ylabel('Preço de fechamento', fontsize = 18)
plt.plot(treinamento['Close'])
plt.plot(df_teste[['Close', 'predicoes']])
plt.legend(['Treinamento', 'Real', 'Prediçoes'], loc=2, prop={'size': 16})
plt.show()

df_teste.sort_index()

df_teste

#o preço é legal, mas o importante e acertar pra qual lado vai o mercado

#calcular media de acertos e expectativa de lucro

df_teste['variacao_percentual_acao'] = df_teste['Close'].pct_change()
df_teste['variacao_percentual_modelo'] = df_teste['predicoes'].pct_change()

df_teste = df_teste.dropna()

df_teste['var_acao_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_acao'] > 0, True, False)
df_teste['var_modelo_maior_menor_que_zero'] = np.where(df_teste['variacao_percentual_modelo'] > 0, True, False)

df_teste['acertou_o_lado'] = np.where(df_teste['var_acao_maior_menor_que_zero'] == df_teste['var_modelo_maior_menor_que_zero'], True, False)

df_teste['variacao_percentual_acao_abs'] = df_teste['variacao_percentual_acao'].abs()

df_teste

acertou_lado = df_teste['acertou_o_lado'].sum()/len(df_teste['acertou_o_lado'])
errou_lado = 1 - acertou_lado

media_lucro = df_teste.groupby('acertou_o_lado')['variacao_percentual_acao_abs'].mean()

exp_mat_lucro = acertou_lado * media_lucro[1] - media_lucro[0] * errou_lado

ganho_sobre_perda = media_lucro[1]/media_lucro[0]

print(media_lucro)
print(ganho_sobre_perda)
print(acertou_lado)
print(exp_mat_lucro * 100)

#criando um codigo que voce passa 60 dias e ele devolve a cotacao
#resumindo: vamos descobrir o da petrobras de hoje/amanha com esse modelo

data_hoje = datetime.now()

#se quise escolher um dia, basta fazer assim

data_hoje = datetime.now() - timedelta(days = 1)

if data_hoje.hour > 18:

    final = data_hoje
    inicial = datetime.now() - timedelta(days = 252)

else:
    final = data_hoje - timedelta(days = 1)
    inicial = datetime.now() - timedelta(days = 252)

cotacoes = yf.download(acao, start=inicio, end=final)
ultimos_60_dias = cotacoes['Close'].iloc[-60:].values.reshape(-1, 1)

ultimos_60_dias_escalados = escalador.transform(ultimos_60_dias)

teste_x = []
teste_x.append(ultimos_60_dias_escalados)
teste_x = np.array(teste_x)
teste_x = teste_x.reshape(teste_x.shape[0], teste_x.shape[1], 1)

previsao_de_preco = modelo.predict(teste_x)
previsao_de_preco = escalador.inverse_transform(previsao_de_preco)

print(previsao_de_preco)

